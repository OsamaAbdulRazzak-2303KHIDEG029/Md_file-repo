{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Create nodes data and nodes from input dir(handle best performing funds too)</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.readers.file.flat import FlatReader\n",
    "from llama_index.core.schema import TextNode, RelatedNodeInfo, NodeRelationship\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.core.vector_stores import (\n",
    "    MetadataFilter,\n",
    "    MetadataFilters,\n",
    "    FilterOperator,\n",
    "    FilterCondition,\n",
    ")\n",
    "from deep_translator import GoogleTranslator\n",
    "from src.config import MONTH_FULL_NAMES, MONTH_PATTERN, YEAR_PATTERN\n",
    "from src.utils import extract_month, extract_year\n",
    "\n",
    "\n",
    "def creat_node_data_from_input_dir(inpur_dir):\n",
    "\n",
    "    documents = SimpleDirectoryReader(\n",
    "        input_dir=inpur_dir,\n",
    "        file_extractor={\n",
    "            \".md\": FlatReader()\n",
    "        },  # This disables the MarkdownReader for .md files\n",
    "        recursive=True,\n",
    "    ).load_data()\n",
    "\n",
    "    nodes_data = []\n",
    "\n",
    "    for document in documents:\n",
    "        markdown_document = document.get_content()\n",
    "        filename = document.metadata.get(\"filename\")\n",
    "        file_id = document.id_\n",
    "        headers_to_split_on = [\n",
    "            (\"#\", \"Header 1\"),\n",
    "            # (\"##\", \"Header 2\"),\n",
    "            # (\"###\", \"Header 3\"),\n",
    "        ]\n",
    "        markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "            headers_to_split_on=headers_to_split_on\n",
    "        )\n",
    "        md_header_splits = markdown_splitter.split_text(markdown_document)\n",
    "\n",
    "        node_data = {\"file_id\": file_id, \"filename\": filename, \"node_text\": []}\n",
    "\n",
    "        for text in md_header_splits:\n",
    "            headers_combined = []\n",
    "\n",
    "            # Loop through metadata and concatenate headers\n",
    "            for _, header in text.metadata.items():\n",
    "                if header:\n",
    "                    headers_combined.append(header)\n",
    "\n",
    "            headers_combined = \" of \".join(headers_combined[::-1])\n",
    "            # Concatenate headers and page content\n",
    "            concat_text = headers_combined + \"\\n\" + text.page_content\n",
    "            node_data[\"node_text\"].append(concat_text)\n",
    "        nodes_data.append(node_data)\n",
    "\n",
    "    return nodes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define patterns for both types of reports\n",
    "pattern_top_performing_with_month_and_year = (\n",
    "    r\"^(Top/Best Performing Funds and Returns for .+?)\\n(\\|.+?)(?=\\n[A-Z#]|$)\"\n",
    ")\n",
    "pattern_top_performing = (\n",
    "    r\"^(Top/Best Performing Funds and Returns)\\n(\\|.+?)(?=\\n[A-Z#]|$)\"\n",
    ")\n",
    "pattern_fund_names = r\"(#?\\s*Name of all Funds offered by AAML.*?Profile)\\n([\\s\\S]*)\"\n",
    "\n",
    "\n",
    "def create_nodes_from_nodes_data(nodes_data):\n",
    "    nodes = []\n",
    "    for data in nodes_data:\n",
    "        filename = data[\"filename\"]\n",
    "        month = extract_month(filename)\n",
    "        year = extract_year(filename)\n",
    "\n",
    "        node_text = data[\"node_text\"][0]\n",
    "\n",
    "        # Try matching \"Top Performing Funds with month and year\"\n",
    "        match_top_performing__with_month_and_year = re.search(\n",
    "            pattern_top_performing_with_month_and_year, node_text, re.DOTALL\n",
    "        )\n",
    "\n",
    "        # Try matching \"Top Performing Funds\"\n",
    "        match_top_performing = re.search(pattern_top_performing, node_text, re.DOTALL)\n",
    "\n",
    "        print(match_top_performing__with_month_and_year)\n",
    "        print(\"---------------------------------------\")\n",
    "\n",
    "        # Try matching \"Name of all Funds offered by AAML\"\n",
    "        match_fund_names = re.search(pattern_fund_names, node_text, re.DOTALL)\n",
    "\n",
    "        if month and year:\n",
    "            if match_top_performing__with_month_and_year:\n",
    "                report_title = match_top_performing__with_month_and_year.group(1)\n",
    "                report_content = match_top_performing__with_month_and_year.group(2)\n",
    "            elif match_fund_names:\n",
    "                report_title = match_fund_names.group(1)\n",
    "                report_content = match_fund_names.group(2)\n",
    "            else:\n",
    "                report_title = None\n",
    "                report_content = None\n",
    "\n",
    "            if report_title and report_content and len(data[\"node_text\"]) == 1:\n",
    "                node = TextNode(\n",
    "                    text=report_title,\n",
    "                    metadata={\n",
    "                        \"year\": str(year),\n",
    "                        \"month\": month,\n",
    "                        \"filename\": filename,\n",
    "                        \"file_id\": data[\"file_id\"],\n",
    "                        \"text_metadata\": report_content,\n",
    "                    },\n",
    "                )\n",
    "                node.excluded_embed_metadata_keys = [\"text_metadata\", \"file_id\"]\n",
    "                node.relationships[NodeRelationship.SOURCE] = RelatedNodeInfo(\n",
    "                    node_id=data[\"file_id\"], metadata={\"filename\": filename}\n",
    "                )\n",
    "                nodes.append(node)\n",
    "\n",
    "            else:\n",
    "                for text in data[\"node_text\"]:\n",
    "                    node = TextNode(\n",
    "                        text=text,\n",
    "                        metadata={\n",
    "                            \"year\": str(year),\n",
    "                            \"month\": month,\n",
    "                            \"filename\": filename,\n",
    "                            \"file_id\": data[\"file_id\"],\n",
    "                        },\n",
    "                    )\n",
    "                    node.excluded_embed_metadata_keys = [\"file_id\"]\n",
    "                    node.relationships[NodeRelationship.SOURCE] = RelatedNodeInfo(\n",
    "                        node_id=data[\"file_id\"], metadata={\"filename\": filename}\n",
    "                    )\n",
    "                    nodes.append(node)\n",
    "        else:\n",
    "            print(\"bro i am here eeee\")\n",
    "\n",
    "            if match_top_performing:\n",
    "                report_title = match_top_performing.group(1)\n",
    "                report_content = match_top_performing.group(2)\n",
    "\n",
    "            elif match_fund_names:\n",
    "                print(\"âœ… Match Found for Fund Names\")\n",
    "                # print(\"Title:\", match_fund_names.group(1))\n",
    "                # print(\"Content:\", match_fund_names.group(2))\n",
    "                report_title = match_fund_names.group(1)\n",
    "                print(\"text:\", report_title)\n",
    "                report_content = match_fund_names.group(2)\n",
    "            else:\n",
    "                report_title = None\n",
    "                report_content = None\n",
    "            if report_title and report_content and len(data[\"node_text\"]) == 1:\n",
    "                node = TextNode(\n",
    "                    text=report_title,\n",
    "                    metadata={\n",
    "                        \"filename\": filename,\n",
    "                        \"file_id\": data[\"file_id\"],\n",
    "                        \"text_metadata\": report_content,\n",
    "                    },\n",
    "                )\n",
    "                node.excluded_embed_metadata_keys = [\"text_metadata\", \"file_id\"]\n",
    "                node.relationships[NodeRelationship.SOURCE] = RelatedNodeInfo(\n",
    "                    node_id=data[\"file_id\"], metadata={\"filename\": filename}\n",
    "                )\n",
    "                nodes.append(node)\n",
    "            else:\n",
    "                for text in data[\"node_text\"]:\n",
    "                    node = TextNode(\n",
    "                        text=text,\n",
    "                        metadata={\n",
    "                            \"filename\": filename,\n",
    "                            \"file_id\": data[\"file_id\"],\n",
    "                        },\n",
    "                    )\n",
    "                    node.excluded_embed_metadata_keys = [\"file_id\"]\n",
    "                    node.relationships[NodeRelationship.SOURCE] = RelatedNodeInfo(\n",
    "                        node_id=data[\"file_id\"], metadata={\"filename\": filename}\n",
    "                    )\n",
    "                    nodes.append(node)\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "path = \"latest_modified_fmr_data/Alfalah_assist_all_tabulor_md_data\"\n",
    "nodes_data = creat_node_data_from_input_dir(path)\n",
    "nodes = create_nodes_from_nodes_data(nodes_data)\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Delete data from Qdrant</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# from src.utils import creat_node_data_from_input_dir, create_nodes_from_nodes_data\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient, models\n",
    "import qdrant_client\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_data_from_qdrant(filename: str):\n",
    "    # Initialize Qdrant client\n",
    "    client = qdrant_client.QdrantClient(url=\"http://65.0.229.53:6333\", port=6333)\n",
    "\n",
    "    COLLECTION_NAME = \"alfalah_investment\"\n",
    "    embed_model_name = \"text-embedding-3-small\"\n",
    "\n",
    "    # Set the embedding model\n",
    "    embed_model = OpenAIEmbedding(model_name=embed_model_name)\n",
    "    Settings.embed_model = embed_model\n",
    "\n",
    "    # Perform the delete operation\n",
    "    try:\n",
    "        response = client.delete(\n",
    "            collection_name=COLLECTION_NAME,  # Use the variable directly\n",
    "            points_selector=models.FilterSelector(\n",
    "                filter=models.Filter(\n",
    "                    must=[\n",
    "                        models.FieldCondition(\n",
    "                            key=\"filename\",\n",
    "                            match=models.MatchValue(value=filename),\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "        print(f\"File for the year '{filename}' has been deleted successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_data_from_qdrant(\"QUERIES_FOR_CHATBOT.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Add data to Qdrant</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def add_data_to_qdrant(path):\n",
    "\n",
    "    client = qdrant_client.QdrantClient(url=\"http://65.0.229.53:6333\", port=6333)\n",
    "\n",
    "    COLLECTION_NAME = \"alfalah_investment\"\n",
    "    embed_model_name = \"text-embedding-3-small\"\n",
    "\n",
    "    embed_model = OpenAIEmbedding(model_name=embed_model_name)\n",
    "    Settings.embed_model = embed_model\n",
    "\n",
    "    vector_store = QdrantVectorStore(client=client, collection_name=COLLECTION_NAME)\n",
    "    nodes_data = creat_node_data_from_input_dir(path)\n",
    "    nodes = create_nodes_from_nodes_data(nodes_data)\n",
    "\n",
    "    print(nodes)\n",
    "\n",
    "    logging.info(\"no collection found\")\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        vector_store=vector_store,\n",
    "    )\n",
    "    index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_data_to_qdrant(\"latest_modified_fmr_data/FAQs/queries for chatbot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
